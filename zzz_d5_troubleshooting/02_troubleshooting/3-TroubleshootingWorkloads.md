# Troubleshooting Pods

- Create the deployment we want to troubleshoot

```shell
kubectl apply -f deployment-1.yaml
```

- Scenario:
You get a call from a user that says none of their pods are up and running can you help?

- Start troubleshooting...

- If no pods are up and running we need to find out why...
No pods are Ready...0/3. 

```shell
kubectl get deployment
```

- If no pods are running let's look at the pods more closely

```shell
kubectl get pods 
```

- It's a bad image (Status is ErrImagePull or ImagePullBackOff)...
This means are image isn't available or we have a config issue in our deployment
Check out the events for more information:
Failed to pull image "ghcr.io/hungtran84/hello-ap:1.0": rpc error: code = Unknown desc = Error response from daemon: manifest for ghcr.io/hungtran84/hello-ap:1.0 not found
It's hello-ap rather than hello-app. 

```shell
kubectl describe pods 
```

- We can also look at the events to get this information

```shell
kubectl get events --sort-by='.metadata.creationTimestamp'
```

- DECLARATIVE SOLUTION:
Apply the corrected manifest which points to the correct image

```shell
kubectl apply -f deployment-1-corrected.yaml
```

- IMPERATIVE SOLUTION:
Change:       - image: ghcr.io/hungtran84/hello-ap:1.0
To:           - image: ghcr.io/hungtran84/hello-app:1.0

```shell
kubectl edit deployment hello-world-1
```

- 3 of 3 should be up and ready!

```shell
kubectl get deployment
```

- Clean up this demo before moving on.

```shell
kubectl delete -f deployment-1-corrected.yaml
```

# Troubleshooting Deployments

- Create the deployment we want to troubleshoot

```shell
kubectl apply -f deployment-2.yaml
```

-Scenario:
You get a call...the pods are up but none are reporting 'Ready' and the app isn't accesible.
Start troubleshooting by looking at why the Pods aren't Ready...all pods are 0/1 Ready meaning the container in the pod isn't ready.

```shell
kubectl get pods 
```

- We can look at kubectl describe  to quickly find out why?  In the Events you see the readiness probe is failing...but why?
What port is the Container Port? What is the Port configured in the Readiness Probe? Do they match?
Readiness probe failed: Get http://192.168.222.225:8081/index.html: dial tcp 192.168.222.225:8081: connect: connection refused

```shell
kubectl describe pods 
```

- DECLARATIVE SOLUTION:
Deploy the corrected readiness probe
This will cause a rollout since the pod spec changed.

```shell
kubectl apply -f deployment-2-corrected.yaml
```

- IMPERATIVE SOLUTION:
This will cause a rollout since the pod spec changed.
In the readinessProbe
CHANGE:             port: 8081
To:                 port: 8080

```shell
kubectl edit deployment hello-world-2
```

- Check the Pods, all should be 1/1 Ready.

```shell
kubectl get pods
```

- Clean up this demo

```shell
kubectl delete -f deployment-2-corrected.yaml
```


# Storage - Failure to access persistant volume storage

- You'll need the NFS server that we configured in the course 'Configuring and Managing Kubernetes Storage and Scheduling' for this demo

- Create the deployment we want to troubleshoot

```shell
kubectl apply -f deployment-3.yaml
```

- Scenario:
You get a call...the pod is scheduled but it is stuck in ContainerCreating Status
Start troubleshooting...by check out the Pods state...ContainerCreated...ok let's check out the events

```shell
kubectl get pods 
```

- Describe pods

```shell
kubectl describe pods 
```

- We can also look at the events to get this information

```shell
kubectl get events --sort-by='.metadata.creationTimestamp'
```

- SOLUTION:

```shell
kubectl apply -f deployment-3-corrected.yaml
```

- This should be up and Running

```shell
kubectl get pods 
```

- Clean up this demo

```shell
kubectl delete -f deployment-3-corrected.yaml
```

# Scheduling

- Create the deployment we want to troubleshoot

```shell
kubectl apply -f deployment-4.yaml
```

- Scenario: User reports that some pods have started and some have not
Start troubleshooting...check out the pods
3 of the 6 pods are pending...why? We should look at the scheduler

```shell
kubectl get pods -o wide
```

Get scheduler events...scroll up do you see any errors?
Look for Warnings and Failures...
0/4 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 3 Insufficient cpu

```shell
kubectl get events --sort-by='.metadata.creationTimestamp'
```

- Let's check out the Pods...what are the CPU Requests? It's current set to 1. How many CPUs are allocatable on the Node? Let's look at the Node for that

```shell
kubectl describe pods
```

- Check out the details of the Node to see it's resource allocations and current requests
How much CPU is Allocatable:? Should be 2 if you're using our lab cluster. 
How much CPU is Allocated? 1250m or 1.25vCPU...we're out of CPU to allocate on the nodes and the three pending pods cannot start up.

```
kubectl describe nodes
```

- DECLARATIVE SOLUTION:
We can either add more CPUs to the cluster or adjust the requests in our Pod Spec.
Let's change the request to 500m or 1/2 a CPU. All pods should start

```
kubectl apply -f deployment-4-corrected.yaml
```

- IMPERATIVE SOLUTION:
In Pod.Spec.Container.Resources.Requests
CHANGE:             cpu: "1"
TO:                 cpu: "500m"

```
kubectl edit deployment hello-world-4 
```

- 6 of 6 pods should be online...this start a rollout because the Pod Spec is updated

```
kubectl get pods 
```

- Let's clean up this demo

```
kubectl delete -f deployment-4-corrected.yaml
```

# Services - mismatching service selector and labels

- Create the deployment we want to troubleshoot

```
kubectl apply -f deployment-5.yaml
```

- Scenario: Pods are all online but users cannot connect to the service
Start troubleshooting...let's see if we can access the service
Get the Service's ClusterIP and store that for reuse.

```
SERVICEIP=$(kubectl get service hello-world-5 -o jsonpath='{ .spec.clusterIP }')
echo $SERVICEIP
```

- Access the service inside the cluster...connection refused...why?

```
curl http://$SERVICEIP
```

- Let's check out the endpoints behind the service...there's no endpoints. Why? 

```
kubectl describe service hello-world-5
kubectl get endpoints hello-world-5
```

- Let's check the labels and selectors for the service and the pods
The selector for the service is Selector:  app=hello-world...now let's check the labels on the Pods

```
kubectl describe service hello-world-5
```

- Do any of the labels match the selector for the service? 
No, the labels on the pods are app=hello-world-5 and the selector is app=hello-world

```
kubectl get pods --show-labels
```

- DECLARATIVE SOLUTION:
We can edit the selector or change the labels...let's change the service selector so the pods don't need to restart

```
kubectl apply -f deployment-5-corrected.yaml
```

- IMPERATIVE SOLUTION:
CHANGE:  selector:
    app: hello-world
TO:  selector:
    app: hello-world-5

```
kubectl edit service hello-world-5
```

-We should have endpoints

```
kubectl get endpoints hello-world-5
```

- Let's access the service, does it work?

```
SERVICEIP=$(kubectl get service hello-world-5 -o jsonpath='{ .spec.clusterIP }')
curl http://$SERVICEIP
```


- Clean up this demo

```
kubectl delete -f deployment-5-corrected.yaml
```

